{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d600741",
   "metadata": {},
   "source": [
    "# Generate Validation .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scaled.dataset.particle_fluid_dataset import ParticleFluidDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "val_dataset = ParticleFluidDataset(\n",
    "        data_dir=\"data/couple_spout_3D\",\n",
    "        skip_timestep=1,\n",
    "        time_steps_list=[i for i in range(200, 250)],\n",
    "    )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "for i, data in enumerate(val_dataloader):\n",
    "    current_data = data[0][0]\n",
    "\n",
    "    current_data_np = current_data.numpy()\n",
    "    np.save(f\"data/evaluation_npy_step200-250/gt_{i:03d}.npy\", current_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486d286",
   "metadata": {},
   "source": [
    "# Generate Whole Rollout .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2518a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ParticleFluidDataset(\n",
    "        data_dir=\"data/couple_spout_3D\",\n",
    "        skip_timestep=1,\n",
    "        time_steps_list=[i for i in range(1, 250)],\n",
    "    )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "for i, data in enumerate(val_dataloader):\n",
    "    current_data = data[0][0]\n",
    "\n",
    "    current_data_np = current_data.numpy()\n",
    "    np.save(f\"data/evaluation_npy_step1-250/gt_{i:03d}.npy\", current_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f203fef",
   "metadata": {},
   "source": [
    "# Generate High Resolution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ecd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def upsample_grid(grid, scale=2):\n",
    "    \"\"\"\n",
    "    Upsample a 3D grid by integer scale, filling new cells with 0.\n",
    "    \"\"\"\n",
    "    D, H, W = grid.shape\n",
    "    new_D, new_H, new_W = D*scale, H*scale, W*scale\n",
    "    up_grid = np.zeros((new_D, new_H, new_W), dtype=grid.dtype)\n",
    "    up_grid[::scale, ::scale, ::scale] = grid\n",
    "    return up_grid\n",
    "\n",
    "def process_folder(input_dir, output_dir, scale=2):\n",
    "    \"\"\"\n",
    "    Process all .npy files in input_dir and save upsampled grids to output_dir.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            grid = np.load(file_path)\n",
    "\n",
    "            up_grid = upsample_grid(grid, scale=scale)\n",
    "\n",
    "            save_path = os.path.join(output_dir, filename)\n",
    "            np.save(save_path, up_grid)\n",
    "            print(f\"Processed {filename} -> {save_path}\")\n",
    "\n",
    "# 使用示例\n",
    "input_dir = \"/root/autodl-tmp/SCALED-Particle/data/couple_spout_3D\"\n",
    "output_dir = \"/root/autodl-tmp/SCALED-Particle/data/high_res\"\n",
    "process_folder(input_dir, output_dir, scale=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e4b65f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scaled.dataset.particle_fluid_dataset import ParticleFluidDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "val_dataset = ParticleFluidDataset(\n",
    "        data_dir=\"data/high_res\",\n",
    "        skip_timestep=1,\n",
    "        time_steps_list=[i for i in range(200, 250)],\n",
    "    )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "for i, data in enumerate(val_dataloader):\n",
    "    current_data = data[0][0]\n",
    "\n",
    "    current_data_np = current_data.numpy()\n",
    "    np.save(f\"data/high_res_npy/gt_{i:03d}.npy\", current_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3782ca",
   "metadata": {},
   "source": [
    "# Generate SFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81e03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def morton_sfc_3d(D, H, W):\n",
    "    \"\"\"\n",
    "    生成任意长方体 (D,H,W) 的 Morton / Z-order SFC 通道\n",
    "    输出 shape: (D,H,W)，归一化到 [0,1]\n",
    "    \"\"\"\n",
    "    # 最大维度决定 bit 数\n",
    "    n = max(D, H, W).bit_length()\n",
    "\n",
    "    def part1by2(n):\n",
    "        n &= 0x1FFFFF\n",
    "        n = (n | (n << 32)) & 0x1F00000000FFFF\n",
    "        n = (n | (n << 16)) & 0x1F0000FF0000FF\n",
    "        n = (n | (n << 8)) & 0x100F00F00F00F00F\n",
    "        n = (n | (n << 4)) & 0x10C30C30C30C30C3\n",
    "        n = (n | (n << 2)) & 0x1249249249249249\n",
    "        return n\n",
    "\n",
    "    vol = np.zeros((D, H, W), dtype=np.float64)\n",
    "\n",
    "    for z in range(D):\n",
    "        for y in range(H):\n",
    "            for x in range(W):\n",
    "                # 映射到 [0, 2^n-1]\n",
    "                xm = int(x * (2**n - 1) / (W - 1)) if W > 1 else 0\n",
    "                ym = int(y * (2**n - 1) / (H - 1)) if H > 1 else 0\n",
    "                zm = int(z * (2**n - 1) / (D - 1)) if D > 1 else 0\n",
    "\n",
    "                idx = part1by2(xm) | (part1by2(ym) << 1) | (part1by2(zm) << 2)\n",
    "                vol[z, y, x] = idx\n",
    "\n",
    "    return torch.from_numpy(vol)\n",
    "\n",
    "morton_sfc = morton_sfc_3d(256, 64, 64)\n",
    "\n",
    "\n",
    "nomalized_sfc = (morton_sfc - morton_sfc.min()) / (morton_sfc.max() - morton_sfc.min())\n",
    "\n",
    "torch.save(nomalized_sfc, \"data/morton_sfc.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
